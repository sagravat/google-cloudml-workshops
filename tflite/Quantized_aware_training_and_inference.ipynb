{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quantized_aware_training_and_inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagravat/google-cloudml-workshops/blob/master/tflite/Quantized_aware_training_and_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe6cQlA7o-xV",
        "colab_type": "text"
      },
      "source": [
        "# Quantized Aware Training with Inference example\n",
        "Demonstrates using the tensorflow model optimization API to perform quantized aware training and use the TF Lite python interpreter to perform inference with a uint8 converted image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5kFEApqpiBq",
        "colab_type": "text"
      },
      "source": [
        "### Install module from github since pypy is not in sync with latest release as of 7/18/2019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrTYgoluMtK2",
        "colab_type": "code",
        "outputId": "8fe36d77-9da8-4aa9-fd0d-0915cd0f2144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install --user -e git://github.com/tensorflow/model-optimization.git@v0.1.2#egg=tensorflow_model_optimization_v0.1.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining tensorflow_model_optimization_v0.1.2 from git+git://github.com/tensorflow/model-optimization.git@v0.1.2#egg=tensorflow_model_optimization_v0.1.2\n",
            "  Cloning git://github.com/tensorflow/model-optimization.git (to revision v0.1.2) to ./src/tensorflow-model-optimization-v0.1.2\n",
            "  Running command git clone -q git://github.com/tensorflow/model-optimization.git /content/src/tensorflow-model-optimization-v0.1.2\n",
            "  Running command git checkout -q c2c0fc1f188685513d32a58b4106ebe40037a307\n",
            "\u001b[33m  WARNING: Generating metadata for package tensorflow-model-optimization-v0.1.2 produced metadata for project name tf-model-optimization-nightly. Fix your #egg=tensorflow-model-optimization-v0.1.2 fragments.\u001b[0m\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tf-model-optimization-nightly) (1.16.4)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tf-model-optimization-nightly) (1.12.0)\n",
            "Requirement already satisfied: enum34~=1.1 in /usr/local/lib/python3.6/dist-packages (from tf-model-optimization-nightly) (1.1.6)\n",
            "Installing collected packages: tf-model-optimization-nightly\n",
            "  Running setup.py develop for tf-model-optimization-nightly\n",
            "Successfully installed tf-model-optimization-nightly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arGshoD_puaf",
        "colab_type": "text"
      },
      "source": [
        "### Make sure to restart the runtime and then you'll see the module in the path below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f902vlFQMzqD",
        "colab_type": "code",
        "outputId": "df4292fa-289d-44d2-daf5-0da865d15f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/root/.local/lib/python3.6/site-packages',\n",
              " '/content/src/tensorflow-model-optimization-v0.1.2',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45G9XQLRpzp9",
        "colab_type": "text"
      },
      "source": [
        "### Verify the module has been installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR-lx8XhM4fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow_model_optimization.python.core.quantization.keras.quantize_emulate import QuantizeEmulate\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAbRlAhBp7Z7",
        "colab_type": "text"
      },
      "source": [
        "## Perform the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLQaUhMPM_zZ",
        "colab_type": "code",
        "outputId": "4622a376-3110-4445-99c7-5c2fe776f1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf  # pylint: disable=g-bad-import-order\n",
        "\n",
        "from tensorflow_model_optimization.python.core.quantization.keras.quantize_emulate import QuantizeEmulate\n",
        "from tensorflow_model_optimization.python.core.quantization.keras.quantize_emulate_wrapper import QuantizeEmulateWrapper\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "  input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "  input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "l = tf.keras.layers\n",
        "quant_params = {'num_bits': 8}\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    QuantizeEmulate(\n",
        "        l.Conv2D(32, 5, padding='same', activation='relu'),\n",
        "        input_shape=input_shape,\n",
        "        **quant_params),\n",
        "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    QuantizeEmulate(\n",
        "        l.Conv2D(64, 5, padding='same', activation='relu'), **quant_params),\n",
        "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    l.Flatten(),\n",
        "    QuantizeEmulate(l.Dense(1024, activation='relu'), **quant_params),\n",
        "    l.Dropout(0.4),\n",
        "    QuantizeEmulate(l.Dense(num_classes), **quant_params),\n",
        "    # TODO(alanchiao): fuse softmax once we've handled it.\n",
        "    l.Softmax(),\n",
        "])\n",
        "\n",
        "# Dump graph to /tmp for verification on tensorboard.\n",
        "graph_def = tf.get_default_graph().as_graph_def()\n",
        "with open('/tmp/mnist_model.pbtxt', 'w') as f:\n",
        "  f.write(str(graph_def))\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adadelta(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Export to Keras.\n",
        "keras_file = '/tmp/quantized_mnist.h5'\n",
        "tf.keras.models.save_model(model, keras_file)\n",
        "\n",
        "# Convert to TFLite model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(\n",
        "    keras_file,\n",
        "    custom_objects={'QuantizeEmulateWrapper': QuantizeEmulateWrapper})\n",
        "converter.inference_type = tf.lite.constants.QUANTIZED_UINT8\n",
        "input_arrays = converter.get_input_arrays()\n",
        "converter.quantized_input_stats = {input_arrays[0]: (0., 255.)}  # mean, std_dev\n",
        "tflite_model = converter.convert()\n",
        "open('/tmp/quantized_mnist.tflite', 'wb').write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 23:14:55.822640 140712049248128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 2.2859 - acc: 0.1362 - val_loss: 2.2624 - val_acc: 0.1693\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 2.2400 - acc: 0.2367 - val_loss: 2.2111 - val_acc: 0.3572\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 2.1836 - acc: 0.3661 - val_loss: 2.1442 - val_acc: 0.5497\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 2.1055 - acc: 0.4894 - val_loss: 2.0481 - val_acc: 0.6643\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 1.9944 - acc: 0.5869 - val_loss: 1.9110 - val_acc: 0.7147\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 1.8430 - acc: 0.6499 - val_loss: 1.7280 - val_acc: 0.7547\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 1.6504 - acc: 0.6860 - val_loss: 1.5043 - val_acc: 0.7761\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 1.4315 - acc: 0.7124 - val_loss: 1.2684 - val_acc: 0.7932\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 1.2206 - acc: 0.7365 - val_loss: 1.0585 - val_acc: 0.8096\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 1.0386 - acc: 0.7596 - val_loss: 0.8904 - val_acc: 0.8265\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.9029 - acc: 0.7755 - val_loss: 0.7653 - val_acc: 0.8405\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.7992 - acc: 0.7939 - val_loss: 0.6748 - val_acc: 0.8516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0718 23:16:13.007611 140712049248128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0718 23:16:13.008793 140712049248128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.6748503169059753\n",
            "Test accuracy: 0.8516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0718 23:16:13.917068 140712049248128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/util.py:238: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0718 23:16:13.918221 140712049248128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3281280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6W91d1zXJDA",
        "colab_type": "code",
        "outputId": "b8d03115-8e39-4a8b-bbcc-c204ba4e3b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /tmp/quantized_mnist.tflite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/quantized_mnist.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmAcexqvqC90",
        "colab_type": "text"
      },
      "source": [
        "## Load the TF lite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cKjFWTBX2lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " interpreter = tf.lite.Interpreter(\"/tmp/quantized_mnist.tflite\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xlG9V5lqIAP",
        "colab_type": "text"
      },
      "source": [
        "### allocate the tensors and get the input/output details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oel0jP5YA4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvgv28YTqNOn",
        "colab_type": "text"
      },
      "source": [
        "### Convert a test image to uint8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RibI6K-d_iW",
        "colab_type": "code",
        "outputId": "6e307529-894a-44d6-f8c9-775c450c0bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = x_test[45].reshape(1, img_rows, img_cols, 1)\n",
        "data = 255 * data # scale by 255\n",
        "img = data.astype(np.uint8)\n",
        "img.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16TrfDTOdYMu",
        "colab_type": "code",
        "outputId": "a7d1a6cb-626b-4aa1-d16f-de55c79293f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pixels = img.reshape((28, 28))\n",
        "plt.imshow(pixels, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff916284f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVnl8MjRe2AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBXKjoFgqZ1I",
        "colab_type": "text"
      },
      "source": [
        "### Run the interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHdq0wGfZEoB",
        "colab_type": "code",
        "outputId": "4128d9fd-b307-4c0a-d5e8-5825ccbdcc56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)\n",
        "interpreter.set_tensor(input_details[0]['index'], img)\n",
        "\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data, \"\\npredicted value: \", np.argmax(output_data))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 9  4  8 57  5 90 16  4 55  8]] \n",
            "predicted value:  5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}